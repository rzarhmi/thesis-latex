<!1,2019082114:52:54>
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0//EN" "http://www.w3.org/TR/REC-html40/strict.dtd">
<html><head><meta name="qrichtext" content="1" /><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><style type="text/css">
p, li { white-space: pre-wrap; }
</style></head><body>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\‎فصل{ادبیات مربوطه}</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%دومین فصل پایان‌نامه به طور معمول به معرفی مفاهیمی می‌پردازد که در پایان‌نامه مورد استفاده قرار می‌گیرند.</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%در این فصل نمونه‌ای از مفاهیم اولیه آورده شده است.</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%----------------------------- مقدمه ----------------------------------</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\‎قسمت{‏شبکه‌های عصبی پیچشی}</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">«پیچش» یک عمل‌گر خطی است که برای توابع ‎n‎ بعدی‎ تعریف ‌می‌شود. ‎‎‏مقدار آن برای توابع‏ تک متغیره از فرمول ‎‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\begin{equation}\label{eqn:conv}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">	‎‎f(t) * g(t) = \int_{-\infty}^{+\infty}f(\tau).g(t - \tau)‎‎‎‎‎‎‎‎‎‎‎‎‎‎d\tau</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\end{equation} ‎‎</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">محاسبه می‌شود.‎\cite{oppenheim}‎‎ ‏همین فرمول با اندکی تغییر برای توابع با دو متغیر (ماتریس‌های دوبعدی) مانند تصاویر‎‎‏‏، به شکل </p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\begin{equation}\label{eqn:‎twoD-‎conv}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">	‎‎x[m, n] * k[m, n] = \sum_{j=-\infty}^{+\infty}\sum_{i=-\infty}^{+\infty}k[i, j].x[m - i, n - j]</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\end{equation} ‎‎</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">تعریف می‌شود.‎\cite{2d_conv_src}‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">در فرمول ‎‎\ref{eqn:‎twoD-‎conv}‎‎‏ اگر ‎‎$x[m, n]‎‎$‎‏ تصویر ورودی باشد‏، به عمل‌وند ‎‎$k[m, n]‎‎$‎ ‏‎ ‎هسته‎‎‎‏ ‎\‏‎LTRfootnote{‎Kernel‎}‏ گفته می‌شود. هسته مربعی به ابعاد ۳‏×۳‎‎‎‎‎‎‎‏، ۵×۵‏ یا ... است که با انتخاب مناسب‏ محتوا و ابعاد آن، تصویر خروجی می‌تواند دارای ویژگی‌های خاص مربوط به تصویر اصلی باشد. مثلا با انتخاب هسته‌ی خاص‏، می‌توان لبه‌ها را در تصویر شناسایی کرد. </p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\شروع{شکل}[ht]‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\‎‏‎c‎enterimg{CNN_‎pic‎}{15cm}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%‎\‎‏شرح{{‎\footnotesize‎ نمای کلی از یک شبکه‌ی پیچشی  ‎\cite{s}‎}‎}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\caption[نمای کلی از یک شبکه‌ی پیچشی]{{‎\footnotesize‎ نمای کلی از یک شبکه‌ی پیچشی  ‎\cite{CNN_structure}‎}}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\‎‏برچسب{شکل:مثال۲}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\پایان{شکل}‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">s‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">ایده‌ی اصلی در ‎CNN‎‏ این‌ است که مقادیر هسته‌ ثابت در نظر گرفته نشود و به‌عنوان پارامترهای شبکه‌ در هر مرتبه‎\‎‏LTRfootnote{‎Iteration‎} به‌روزرسانی شوند.‎\cite{goodfellow}‎ به‌عنوان مثال‏، پیچش‎\‎‏LTRfootnote{‎Convolve‎}‎‏ تصویر با ابعاد ۱۹۲۰×۲۱۸۰ ‎‏با‎ هسته‌ای به ابعاد ۳×۳‏ را در نظر بگیرید. این شبکه‌ی ساده و تک‌لایه ۹ پارامتر دارد که می‌توان با تعریف تابع هزینه‌ی مناسب‏، برای رسیدن به خروجی مطلوب‏، مدام این ۹ پارامتر را تغییر داد. شکل ‎\ref{شکل:مثال۲}‎ ‎‎نمای کلی از یک ‎CNN‎‏ نشان می‌دهد. </p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‏‎</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">یک ‎CNN‎‏ اغلب از ‎‎‏سه دسته لایه تشکیل می‌شود. لایه‌های پیچشی\‏LTRfootnote{‎Convolutional ‎Layers‎‎}‏، لایه‌های ادغام‎\‎‏LTRfootnote{‎Pooling Layers‎} ‏و لایه‌ها‎ی کاملا متصل‎\‎‏LTRfootnote{‎Fully Connected ‎Layers‎‎}‏. ‏توضیح هر کدام از این لایه‌ها به اختصار آمده‌ است.</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">ایده‌ی کلی پشت لایه‌های پیچشی‏، همان ایده‌ی اصلی CNN‎‏ است.‎ به ازای هر لایه در این دسته از لایه‌ها‏، یک یا چند هسته وجود دارد که تصویر را فیلتر می‌کنند. در نتیجه‌ی این فیلتر ‏برخی از ویژگی‌های تصویر استخراج می‌شود و تصویر کاهش اندازه می‌دهد. هرچند اگر تصویر از‏ چندین کانال‎\‎‏LTRfootnote{‎Channel‎} تشکیل شده باشد‏، تعداد این کانال‌ها رفته رفته بیش‌تر خواهد شد. در ابتدا اکثر تصاویر شامل سه کانال قرمز‏، سبز و آبی‎\LTRfootnote{RGB Channels‎‏ خواهند بود.</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">}‎ هستند. </p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">برخی از لایه‌ها عمل «ادغام»‎\‎‏LTRfootnote{‎Pooling‎}‏ را نیز بر روی تصویر انجام می‌دهند. ادغام انواع مختلفی همانند «ادغام بیشینه»‎\‎‏LTRfootnote{‎Max Pooling‎}‏، «ادغام میانگین»\‏LTRfootnote{‎Average Pooling‎} و ... دارد. به عنوان مثال ‏اگر بخواهیم با یک فیلتر به‌اندازه‌ی ۳×۳‏، تصویری به اندازه‌ی ‎H‎‏×‎W‎‏ را ادغام بیشینه کنیم‏، بایستی از گوشه‌ی سمت چپ تصویر شروع کرده و فیلتر را بر روی تصویر بگذاریم. بیشینه مقدار پیکسل‌هایی از تصویر که زیر فیلتر قرار گرفته‌اند‏، پیکسل اولِ خروجی خواهد بود. سپس فیلتر را یک پیکسل به راست انتقال می‌دهیم و ... . دقت شود که محتویات هسته در عمل ‎‎‏ادغام اهمیتی ندارد. به همین دلیل در ادغام کردن‏، پارامتری برای یادگیری وجود نخواهد داشت. </p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">لایه‌های کاملا متصل بعد از لایه‌های پیچشی و لایه‌های ادغام در ‎CNN‎‏ قرار می‌گیرند. بعد از چندین لایه‌ی پیچشی و ادغام‏، تمامی پیکسل‌های خروجی را به یک شبکه‌ی کاملا متصل (مانند شبکه‌ی ‎‎‏رگرسیون خطی‎\‎‏LTRfootnote{‎Linear Regression‎})‏ می‌دهند تا خروجی نهایی بعد از چندین لایه‌ی کاملا متصل‏ به دست آید. الگوریتم یادگیری برای این لایه‌ها مانند الگوریتم‏‌های‎‎ معمول برای شبکه‌های عصبی ساده‌ای چون رگرسیون خطی است. </p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%\begin{figure}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%\enterimg{CNN_overview.pdf}{15cm}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎%\caption{{‎\footnotesize‎ نمای کلی از یک شبکه‌ی پیچشی  ‎\cite{s}‎}}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎%\label{fig:CNN}‎‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">%\end{figure}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\‎قسمت{‏شبکه‌های عصبی گراف-پیچشی}	</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‏امروزه بسیاری از مجموعه ‌داده‌های موجود‏، مثل اطلاعات شبکه‌های اجتماعی‏، شبکه‌ی اینترنت و ... به شکل گراف هستند.‎\cite{gcn_paper}‎ همان‌گونه که ‎‏پیش‌ از این ذکر شد‏، ‏شبکه‌های عصبی گراف-پیچشی‏، که به اختصار ‎GCN‎‏ نامیده می‌شوند‏، تعمیمی بر ‎CNN‏‎ هستند‎‎ که در آن ورودی به‌جای تصویر‏، یک گراف است. هرچند تفاوت‌ها در همین‌جا به انتها نمی‌سد و پیچیدگی‌های ساختار‎‏ی یک گراف‏، دشواری‌های خاصی را به این شبکه‌ها تحمیل کرده است. ‏شکل ‎\ref{‎‏شکل:گراف}‎‏، نمایی کلی از یک ‎GCN‎‏ را نمایش می‌دهد. ‎‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\begin{figure}‎[ht]‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\centerimg{gcn_web}‎{10cm}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\caption[‏نمای کلی از یک ‎GCN]{{\footnotesize ‏نمای کلی از یک ‎GCN‎}‏ ‎‎\cite{GNN_structure}‎‎}‎‎‏‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎\label{‎‏شکل:گراف}‎‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\end{figure}‎‎‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">به‌صورت دقیق هر ‎GCN‎‏‏ دو ماتریس را به‌عنوان ورودی دریافت می‌کند. </p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎\begin{itemize}</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\item‎‏  ماتریس ‎‎$X‎‎$‎‎‎‎ به ابعاد ‎‎$‎‎N\times F_0‎‎‎$‎‏ که ‎‏‎‎$N$‎ ‏تعداد رئوس و ‎‎$F_0‎‎$‎ ‏تعداد ویژگی‌های ورودی‎\‎‏LTRfootnote{‎Input Features‎}‏ برای هر راس است. </p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\item‎‏  ماتریس مجاورتِ ‎‎$A‎‎$‎ به ابعا‎‏د ‎‎$N‎\times ‎N‎‎‎$‎ ‏که ساختار کلی گراف را مشخص می‌کند.</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\end{itemize}‎‎‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‏حال با تعریف وزن (هسته‌ی) مناسب برای هر لایه از شبکه‏، می‌توان شبکه را آموزش‎\‎‏LTRfootnote{‎Train‎} داد. هرچند هنوز هم برخی از مشکلات برای شبکه‌های نسبتا بزرگ وجود دارد. مشکلاتی که در این پروژه به آن‌ها برخورد شد و راه‌حل پیشنهادی‏ به شرح زیر هستند.</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎\begin{itemize}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\item‎‏ همان‌گونه که ذکر شد‏، یکی از ورودی‌های شبکه‏، ماتریس مجاورت گراف است. در صورتی که یک راس یال بازگشتی به خودش نداشته باشد‏، درایه‌ی نظیر آن راس در ماتریس مجاورت صفر خواهد بود. همین موضوع باعث می‌شود که در مسیر لایه‌های شبکه‏، تنها‎‎‎ ویژگی‌های ورودی رئوس مجاور آن راس در درایه‌ی نظیر آن وجود ‏داشته باشند. به‌عبارت دیگر بعد از طی یک لایه‏، ویژگی‌های رئوس بدون یال بازگشتی‏ تقریبا فراموش خواهند شد. به همین دلیل‏، قبل از هرکاری به تمامی رئوس گراف یک یال بازگشتی اضافه می‌شود. این کار با جمع کردن ماتریس مجاورت با ماتریس واحد (‎$I$‎)‏ انجام می‌گیرد.</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\item ‎‏رئوس‎ با درجه‌ی بالاتر(پایین‌تر) رفته رفته اندازه‌ی بزرگ‌تری (کوچک‌تری) خواهند داشت. به این موضوع انفجارگرادیان‎\‎‏LTRfootnote{‎Exploding Gradient‎}‎‎‎‎‏ و میرایی گرادیان‎\‎‏LTRfootnote{‎Vanishing Gradient‎}  گفته می‌شود. به همین دلیل عادی‌سای‎\LTRfootnote{Normalization}‎ ورودی شبکه‏ یک موضوع اجتناب‌ناپذیر است. ‏برای‎ این کار از روش موجود در ‎\cite{gcn_paper}‎ استفاده شده است.</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\end{itemize}‎‎‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎\section{‎‏مدل‌های توجه}‎‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎‏معماری‌ها و مدل‌هایی که پیش‌تر معرفی شد‏، تفاوتی بین نقاط مختلف یک تصویر یا ویدیو قائل نبودند. درحالی که برای انجام یک الگوریتم بر روی تصویر‏، برخی جزئیات نه‌تنها مهم نیستند‏، بلکه در نتیجه‌ی نهایی خلل ایجاد می‌کنند.‎\cite{lstm_attention}‎ به‌عنوان مثال در فرآیند تشخیص تصویر، پس‌زمنیه‌ی شی موردنظر اهمیتی ندارد. هم‌چنین در مثال خاص این پروژه‏‏، وقتی که کنش صورت‌گرفته دست‌زدن است‏، مفاصل پای یک شخص اهمیت چندانی ندارد. به همین دلیل، برای بهینه‌سازی بیش‌تر و درصد خطای پایین‌تر‏، بهتر است که شبکه رفته رفته متوجه شود که به کدام یک از جزئیات تصویر یا ویدیو بیش‌تر از باقی اجزا اهمیت قائل شود.</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎‎\begin{figure}</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\centerimg{LSTM_attention}{10cm}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\caption[‎‏مدل توجه با استفاده از حافظه‌ی زمینه‌ی سراسری در یک ‎LSTM‏ ‎]{‎‏مدل توجه با استفاده از حافظه‌ی زمینه‌ی سراسری در یک ‎LSTM‏ ‎\cite{lstm_attention}‎‎}‎‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‎\label{fig:attention_LSTM}‎</p>
<p style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">\end{figure}‎‎</p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">یکی از مدل‌های توجه استفاده‌شده‌‏، مدل موجود در ‎\cite{lstm_attention}‎ است که در معماری ‎LSTM‎‏ به کار گرفته شده است. در این مدل علاوه بر دروازه‌های موجود معماری ‎LSTM‎ ‏، یک حافظه‌ی زمینه‌ی سراسری‎\‎‏LTRfootnote{‎Global Context Memory‎}‏ هم اضافه شده است. هم‌چنین از دو لایه ‎LSTM‎‏ استفاده شده است که لایه‌ی اول این حافظه را مقداردهی اولیه می‎‎‏کند و لایه‌ی دوم آن را بهبود می‌بخشد. در نهایت مقدار این حافظه است که به ‏دسته‌بند بیشینه‌ی هموار‎\‎‏LTRfootnote{‎Softmax ‎Classifier‎} ‏‎‎‏داده می‌شود تا خروجی مورد نظر حاصل شود. طریقه‌ی مقداردهی و بهبودبخشی به حافظه‏، روشی مشابه دروازه‌های معمول ‎LSTM‎‏ دارد‎‏. ‏تصویر ‎‎\ref{fig:attention_LSTM}‎‎‏ استفاده از این مدل توجه را نمایش می‌دهد.</p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">روش دیگر ‏به‌کارگیری مدل توجه (که در این پروژه هم از آن استفاده شده است) استفاده از پارامترهای قابل آموزش به‌ازای هر مفصل است. این مدل مناسب شبکه‌های ‎CNN‎‏ یا مشتقات آن مانند ‎GCN‎‏ است.‎\cite{st-gcn}‎ در این مدل‏، از پارامترهای منسوب به وزن‌های اهمیت مفصل ‎\‎‏LTRfootnote{‎Edge Importance Weighting‎}‏ استفاده می‌شود که به هر مفصل یک وزن مشخص می‌دهد. این وزن بعد از آموزش کل شبکه مقدار بهینه پیدا می‌کند. سپس در هنگام ‎‎‏ارزیابی‏، این وزن بر روی هسته‌ی موجود در شبکه‌ی ‎GCN‎‏ ضرب می‌شود تا هر ‎‎‏یال تاثیر مشخصی بر روی جواب نهایی شبکه داشته باشد. </p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p dir='rtl' style=" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;">‏روش دیگری که در حوزه‌ی پردازش تصویر بسیار جدید است‏، استفاده از لایه‌ی خاصی به اسم لایه‌ی ادغام توجه‎\‎‏LTRfootnote{‎Attention Pooling Layer‎} است.‏ اولین استفاده از این روش در بازشناسی کنش انسان در \cite{attention_pooling_main} صورت گرفته است. در این ‎‎‏روش‏، لایه‌های کاملا متصل‏ از لایه‌های پیچشی تغذیه نمی‌شوند. بلکه قبل از لایه‌های کاملا متصل‏، خروجی‌های لایه‌های پیچشی به لایه‌های ادغام توجه داده می‌شود. در‎ این گونه از لایه‌های ادغام‏، کل ‎‎‏ورودی تحت ادغام قرار می‌گیرد و خروجی آن به لایه‌های کاملا متصل یا به یک لایه‌ی دسته‌بند بیشینه‌ی هموار داده می‌شود. (به تفاوت این نوع ادغام با گونه‌های قبلا معرفی شده توجه شود که در گونه‌های قبلی‏، مربع‌های ‎‎$‎‎k\times k$‎ ‏‎از گوشه‌ی سمت بالا-چپ تصویر انتخاب شده و تحت ادغام قرار می‌گیرند). جز‌ئیات این روش در فصل آتی توضیح داده خواهند شد. </p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p>
<p style="-qt-paragraph-type:empty; margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px; -qt-user-state:0;"></p></body></html>